{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def read_image_captions(folder_path):\n",
    "    image_captions = {}\n",
    "\n",
    "    for file in Path(folder_path).glob(\"*.jsonl\"):\n",
    "        file_image_captions = read_jsonl_to_list(file)\n",
    "        file_base, extension = os.path.splitext(os.path.basename(file))\n",
    "        image_captions[file_base] = file_image_captions\n",
    "    return image_captions\n",
    "\n",
    "def read_jsonl_to_list(file_path):\n",
    "    result = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                json_obj = json.loads(line)\n",
    "                for key, value in json_obj.items():\n",
    "                    result.append([key.split('.')[0], value])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping invalid JSON line: {line}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "image_captions = read_image_captions(\"data/image-caption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "device = torch.device(\"cuda\")\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \"\"\n",
    "inputs_sample = tokenizer(text_input, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs_sample = {k: v.to(device) for k, v in inputs_sample.items()}  # Move input tensors to GPU\n",
    "outputs_sample = model(**inputs_sample)\n",
    "embeddings_sample = outputs_sample.last_hidden_state.mean(dim=1).detach().cpu().numpy()\n",
    "\n",
    "max_caption = None\n",
    "max_score = 0\n",
    "\n",
    "# Assuming image_captions is defined elsewhere in your code\n",
    "for video in image_captions:\n",
    "    for caption in image_captions[video]:\n",
    "        inputs_candidate = tokenizer(caption, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs_candidate = {k: v.to(device) for k, v in inputs_candidate.items()}  # Move input tensors to GPU\n",
    "        outputs_candidate = model(**inputs_candidate)\n",
    "        embeddings_candidate = outputs_candidate.last_hidden_state.mean(dim=1).detach().cpu().numpy()\n",
    "        \n",
    "        similarity = np.dot(embeddings_sample, embeddings_candidate.T) / (np.linalg.norm(embeddings_sample) * np.linalg.norm(embeddings_candidate))\n",
    "        \n",
    "        if similarity[0][0] > max_score:\n",
    "            max_score = similarity[0][0]\n",
    "            max_caption = caption\n",
    "print(max_caption)\n",
    "print(max_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "\n",
    "def load_image(path):\n",
    "    return Image.open(path)\n",
    "\n",
    "img_paths = [\n",
    "    \"data/train/African_crocodile/n01697457_85.JPEG\", # crocodile\n",
    "    \"data/train/bullet_train/n02917067_1400.JPEG\", # bullet train\n",
    "    \"data/train/comic_book/n06596364_3314.JPEG\" # comic books \n",
    "]\n",
    "\n",
    "images = [load_image(img) for img in img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image, ImageFile\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "img_model = SentenceTransformer('clip-ViT-B-32')\n",
    "text_model = SentenceTransformer('sentence-transformers/clip-ViT-B-32-multilingual-v1')\n",
    "img_embeddings = img_model.encode(images)\n",
    "\n",
    "texts = [\n",
    "    \"a crocodile\",\n",
    "    \"a bullet train\",\n",
    "    \"comic books.\"\n",
    "]\n",
    "\n",
    "text_embeddings = text_model.encode(texts)\n",
    "cos_sim = util.cos_sim(text_embeddings, img_embeddings)\n",
    "\n",
    "for text, scores in zip(texts, cos_sim):\n",
    "    max_img_idx = torch.argmax(scores)\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Score:\", scores[max_img_idx] )\n",
    "    print(\"Path:\", img_paths[max_img_idx], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

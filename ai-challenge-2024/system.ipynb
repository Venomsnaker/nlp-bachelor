{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def load_clip_features(folder_path):\n",
    "    embeddings = {}\n",
    "    embeddings_map = {}\n",
    "    i = 0\n",
    "\n",
    "    for file in Path(folder_path).glob('*.npy'):\n",
    "        embedding = np.load(str(file))\n",
    "        embedding = embedding.astype(np.float32)\n",
    "        embeddings[i] = embedding\n",
    "        embeddings_map[i] = str(file)\n",
    "        i += 1\n",
    "    return embeddings, embeddings_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data/clip-features-32'\n",
    "embeddings, embeddings_map = load_clip_features(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_keyframes_map(folder_path):\n",
    "    keyframes_map = {}\n",
    "\n",
    "    for file_name in Path(folder_path).glob('*.csv'):\n",
    "        df = pd.read_csv(file_name, index_col=None, header=0)\n",
    "        file_name = os.path.basename(file_name)\n",
    "        file_base, extension = os.path.splitext(file_name)\n",
    "        keyframes_map[file_base] = df\n",
    "    return keyframes_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data/map-keyframes'\n",
    "keyframes_map = load_keyframes_map(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "folder_path = \"data/pack3-groupA\"\n",
    "\n",
    "def load_query(folder_path):\n",
    "    queries = []\n",
    "\n",
    "    # Set up translation model\n",
    "    model_name = \"VietAI/envit5-translation\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)  \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    model = model.to('cuda')\n",
    "\n",
    "    for file in Path(folder_path).glob('*.txt'):\n",
    "        with open(file, \"r\") as file:\n",
    "            # Get query text\n",
    "            text = \"\".join(file.read().splitlines())\n",
    "            model_output = model.generate(tokenizer(text, return_tensors=\"pt\", padding=True).input_ids.to('cuda'), max_length=512)\n",
    "            text_en = tokenizer.batch_decode(model_output, skip_special_tokens=True)[0]\n",
    "            text_en = text_en.replace(\"en: \", \"\")\n",
    "\n",
    "            # Get query type\n",
    "            file_name = os.path.basename(file.name)\n",
    "            base, extension = os.path.splitext(file_name)\n",
    "            query_type = base.split(\"-\")[-1]\n",
    "            \n",
    "            queries.append([text_en, query_type, base])\n",
    "    return queries\n",
    "queries = load_query(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_image_from_path(path, size):\n",
    "    img = Image.open(path).convert('RGB').resize(size)\n",
    "    return np.array(img)\n",
    "\n",
    "def plot_results(results, query_folder_path, keyframes_map):\n",
    "    result_sample = 50\n",
    "    results = results[:result_sample]\n",
    "    fig = plt.figure(figsize=(10, result_sample))\n",
    "    num_images = len(results)\n",
    "    rows = (num_images + 1) // 2\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        ax = fig.add_subplot(rows, 2, i+1)\n",
    "        base, keyframe_id, score = results[i][0], results[i][1], round(results[i][2],3)\n",
    "\n",
    "        chunk_id = \"keyframes_\" + base.split('_')[0]\n",
    "        keyframe_id = keyframes_map[base].loc[keyframes_map[base]['n'] == keyframe_id]['n'].values[0]\n",
    "        keyframe_id = \"%03d\" % keyframe_id + \".jpg\"\n",
    "        query_path = os.path.join('',*[query_folder_path, chunk_id, \"keyframes\", base, keyframe_id])\n",
    "        \n",
    "        ax.imshow(read_image_from_path(query_path, size=(1024, 1024)))\n",
    "        title = Path(query_path).parts\n",
    "        ax.set_title(f\"Top {i+1} - {score}: {title[4]} - {title[5]}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_results(results, output_data_path, keyframes_map, query_name):\n",
    "    query_folder_path = 'data/keyframes'\n",
    "    query_type = query_name.split(\"-\")[-1]\n",
    "    query_name = query_name + \".csv\";\n",
    "    output_data_path = output_data_path + \"/\" + query_name    \n",
    "    with open(output_data_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "\n",
    "        for result in results:\n",
    "            base = result[0]\n",
    "            keyframe_id = result[1]\n",
    "            frame_idx = keyframes_map[base].loc[keyframes_map[base]['n'] == keyframe_id]['frame_idx'].values[0]\n",
    "\n",
    "            if query_type == \"qa\":\n",
    "                ans = result[3]\n",
    "                writer.writerow([base, frame_idx, ans])\n",
    "            elif query_type == \"kis\":\n",
    "                writer.writerow([base, frame_idx])\n",
    "\n",
    "            # chunk_id = \"keyframes_\" + base.split('_')[0]\n",
    "            # keyframe_id = keyframes_map[base].loc[keyframes_map[base]['n'] == keyframe_id]['n'].values[0]\n",
    "            # keyframe_id = \"%03d\" % keyframe_id + \".jpg\"\n",
    "            # query_path = os.path.join('',*[query_folder_path, chunk_id, \"keyframes\", base, keyframe_id])\n",
    "            # title = Path(query_path).parts\n",
    "            # quote = title[4] + \"-\" + title[5]\n",
    "\n",
    "            # if query_type == \"qa\":\n",
    "            #     ans = result[3]\n",
    "            #     writer.writerow([base, quote, ans])\n",
    "            # elif query_type == \"kis\":\n",
    "            #     writer.writerow([base, quote])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import nltk\n",
    "from PIL import Image\n",
    "import re\n",
    "# nltk.download('punkt')\n",
    "\n",
    "def process_kis(query_text, embeddings, sample_per_video, results_size):\n",
    "    print(query_text)\n",
    "\n",
    "    results = []\n",
    "    text_model = SentenceTransformer('sentence-transformers/clip-ViT-B-32')\n",
    "    text_embedding = text_model.encode(query_text)\n",
    "\n",
    "    for i in range (len(embeddings)):\n",
    "        scores = util.cos_sim(text_embedding, embeddings[i])            \n",
    "        scores_top = torch.topk(scores.flatten(), sample_per_video).indices\n",
    "\n",
    "        for j in range(len(scores_top)):\n",
    "            score_raw = scores[0][scores_top[j]].item()\n",
    "            keyframe_id = scores_top[j].item() + 1\n",
    "            file_name = os.path.basename(embeddings_map[i])\n",
    "            file_base, extension = os.path.splitext(file_name)\n",
    "\n",
    "            if (len(results) < results_size):\n",
    "                results.append([file_base, keyframe_id, score_raw])\n",
    "                results = sorted(results, key = lambda item: item[-1])\n",
    "                continue\n",
    "            elif (score_raw > results[0][-1]):\n",
    "                results.pop(0)\n",
    "                results.append([file_base, keyframe_id, score_raw])\n",
    "                results = sorted(results, key = lambda item: item[-1])\n",
    "    return results\n",
    "\n",
    "def process_qa(query_text, query_folder_path, embeddings, sample_per_video, results_size, processor_qa, model_qa):\n",
    "    prompts = []\n",
    "    questions = []\n",
    "    results = []\n",
    "\n",
    "    tokens = nltk.sent_tokenize(query_text)\n",
    "    for token in tokens:\n",
    "        if '?' in token:\n",
    "            questions.append(token)\n",
    "        else:\n",
    "            prompts.append(token)\n",
    "\n",
    "    query_prompt = \" \".join(prompts)\n",
    "    query_question = \" \".join(questions)\n",
    "    query_question += \" Output in only numbers.\"\n",
    "\n",
    "    # results = process_kis(query_prompt, embeddings, sample_per_video, results_size)\n",
    "    results = process_kis(query_text, embeddings, sample_per_video, results_size)\n",
    "    print(query_question)\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        base, keyframe_id = results[i][0], results[i][1]\n",
    "        chunk_id = \"keyframes_\" + base.split('_')[0]\n",
    "        keyframe_id = keyframes_map[base].loc[keyframes_map[base]['n'] == keyframe_id]['n'].values[0]\n",
    "        keyframe_id = \"%03d\" % keyframe_id + \".jpg\"\n",
    "        query_path = os.path.join('',*[query_folder_path, chunk_id, \"keyframes\", base, keyframe_id])\n",
    "        \n",
    "        image = Image.open(query_path).convert('RGB')\n",
    "        inputs = processor_qa(image, query_question, return_tensors=\"pt\").to(\"cuda\")\n",
    "        out = model_qa.generate(**inputs)\n",
    "        generated_text = processor_qa.decode(out[0], skip_special_tokens=True)\n",
    "        numbers = re.findall(r'\\d+', generated_text)\n",
    "        results[i].append(\"\".join(numbers))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "import open_clip\n",
    "from PIL import Image, ImageFile\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "\n",
    "text_model = SentenceTransformer('sentence-transformers/clip-ViT-B-32')\n",
    "processor_qa = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model_qa = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(\"cuda\")\n",
    "\n",
    "query_folder_path = \"data/keyframes\"\n",
    "output_folder_path = \"data/submission\"\n",
    "results_size = 100\n",
    "sample_per_video = 3\n",
    "i = 1\n",
    "\n",
    "for query in queries:\n",
    "    query_text = query[0]\n",
    "    query_type = query[1]\n",
    "    query_name = query[2]\n",
    "    print(\"Query: \", query_name)\n",
    "\n",
    "    if (query_type == 'kis'):\n",
    "        results = process_kis(query_text, embeddings, sample_per_video, results_size)\n",
    "        results = sorted(results, key = lambda item: item[-1], reverse=True)\n",
    "        plot_results(results, query_folder_path, keyframes_map)\n",
    "        save_results(results, output_folder_path, keyframes_map, query_name)\n",
    "    elif query_type == 'qa':\n",
    "        results = process_qa(query_text, query_folder_path, embeddings, sample_per_video, results_size, processor_qa, model_qa)\n",
    "        results = sorted(results, key = lambda item: item[-2], reverse=True)\n",
    "        plot_results(results, query_folder_path, keyframes_map)\n",
    "        save_results(results, output_folder_path, keyframes_map, query_name)\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
